{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''4) Sentiment Analysis'''\n",
    "\n",
    "'''\n",
    "This file takes the user level cleaned data from 1) Data Prep and preforms unsupervised sentiment analysis on it. \n",
    "The code uses three seperate lexicon based scoring methods and compares the results across the users. \n",
    "\n",
    "The code does the following:\n",
    " - Import libraries\n",
    " - Defines functions\n",
    " - Subsets and formats the data. This process uses the cleaned and processed data, not the raw comments.\n",
    " - Scores the data\n",
    " - Compares the scored sentiment accoring to 1) overal and 2) MBTI type.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Libaries and Modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import nltk\n",
    "\n",
    "from afinn import Afinn\n",
    "afn = Afinn(emoticons=False) \n",
    "\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from normalization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Functions\n",
    "def analyze_sentiment_sentiwordnet_lexicon(review):\n",
    "    # tokenize and POS tag text tokens\n",
    "    text_tokens = nltk.word_tokenize(review)\n",
    "    tagged_text = nltk.pos_tag(text_tokens)\n",
    "    pos_score = neg_score = token_count = obj_score = 0\n",
    "    # get wordnet synsets based on POS tags\n",
    "    # get sentiment scores if synsets are found\n",
    "    for word, tag in tagged_text:\n",
    "        ss_set = None\n",
    "        if 'NN' in tag and swn.senti_synsets(word, 'n'):\n",
    "            ss_set = list(swn.senti_synsets(word, 'n'))\n",
    "        elif 'VB' in tag and swn.senti_synsets(word, 'v'):\n",
    "            ss_set = list(swn.senti_synsets(word, 'v'))\n",
    "        elif 'JJ' in tag and swn.senti_synsets(word, 'a'):\n",
    "            ss_set = list(swn.senti_synsets(word, 'a'))\n",
    "        elif 'RB' in tag and swn.senti_synsets(word, 'r'):\n",
    "            ss_set = list(swn.senti_synsets(word, 'r'))\n",
    "        # if senti-synset is found        \n",
    "        if ss_set:\n",
    "            ss_set = ss_set[0]\n",
    "            # add scores for all found synsets\n",
    "            pos_score += ss_set.pos_score()\n",
    "            neg_score += ss_set.neg_score()\n",
    "            obj_score += ss_set.obj_score()\n",
    "            token_count += 1\n",
    "    \n",
    "    # aggregate final scores\n",
    "    try:\n",
    "        final_score = pos_score - neg_score\n",
    "        norm_final_score = round(float(final_score) / token_count, 2)\n",
    "        final_sentiment = 'positive' if norm_final_score >= 0 else 'negative'\n",
    "    except:\n",
    "        final_sentiment = 'Not Evaluated'\n",
    "        \n",
    "    return final_sentiment\n",
    "\n",
    "def analyze_sentiment_vader_lexicon(review, \n",
    "                                    threshold=0.1):\n",
    "    # analyze the sentiment for review\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(review)\n",
    "    # get aggregate scores and final sentiment\n",
    "    agg_score = scores['compound']\n",
    "    final_sentiment = 'positive' if agg_score >= threshold\\\n",
    "                                   else 'negative'\n",
    "   \n",
    "    return final_sentiment\n",
    "\n",
    "def freq(lst):\n",
    "    d = {}\n",
    "    for i in lst:\n",
    "        if d.get(i):\n",
    "            d[i] += 1\n",
    "        else:\n",
    "            d[i] = 1\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   type                                              posts  type_enc  \\\n",
      "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...         8   \n",
      "1  ENTP  'I'm finding the lack of me in these posts ver...         3   \n",
      "\n",
      "                                             comment  \\\n",
      "0  'url url enfp and intj moments url sportscente...   \n",
      "1  'I'm finding the lack of me in these posts ver...   \n",
      "\n",
      "                                       clean_comment  \n",
      "0  url url enfp intj moment url sportscenter top ...  \n",
      "1  find lack post alarm sex bore position often e...  \n",
      "\n",
      "   type                                              posts  type_enc  \\\n",
      "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...         8   \n",
      "1  ENTP  'I'm finding the lack of me in these posts ver...         3   \n",
      "\n",
      "                                             comment     0     1     2      3  \\\n",
      "0  'url url enfp and intj moments url sportscente...   url   url  enfp   intj   \n",
      "1  'I'm finding the lack of me in these posts ver...  find  lack  post  alarm   \n",
      "\n",
      "        4     5  ...    886   887   888   889   890   891   892   893   894  \\\n",
      "0  moment   url  ...   None  None  None  None  None  None  None  None  None   \n",
      "1     sex  bore  ...   None  None  None  None  None  None  None  None  None   \n",
      "\n",
      "    895  \n",
      "0  None  \n",
      "1  None  \n",
      "\n",
      "[2 rows x 900 columns]\n"
     ]
    }
   ],
   "source": [
    "#Load Data\n",
    "cleaned_mbti_userlvl = pd.read_pickle('cleaned_mbti_userlvl.pkl')\n",
    "comments = np.array(cleaned_mbti_userlvl['clean_comment']) #Cast to an array\n",
    "print(cleaned_mbti_userlvl.head(2))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AFINN Sentiment Analysis Scoring\n",
    "afinn_score = [afn.score(review) for review in comments]\n",
    "\n",
    "afinn_score_final = []\n",
    "\n",
    "for x in afinn_score:\n",
    "    if x > 0:\n",
    "        hold = 'positive'\n",
    "    else:\n",
    "        hold = \"negative\"\n",
    "    afinn_score_final.append(hold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sentiment Analysis using Vader Lexicon\n",
    "vader_predictions = [analyze_sentiment_vader_lexicon(review, threshold=0.1) for review in comments] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sentiment Analysis using SentiWord Lexicon\n",
    "sentiwordnet_predictions = [analyze_sentiment_sentiwordnet_lexicon(review) for review in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "afinn_score 8675\n",
      "['positive', 'positive', 'positive', 'positive', 'positive']\n",
      "vader_predictions 8675\n",
      "['positive', 'positive', 'positive', 'positive', 'positive']\n",
      "sentiwordnet_predictions 8675\n",
      "['positive', 'positive', 'positive', 'positive', 'positive']\n"
     ]
    }
   ],
   "source": [
    "#Print Scores for first five\n",
    "print('afinn_score ' + str(len(afinn_score_final)))\n",
    "print(afinn_score_final[:5])\n",
    "\n",
    "print('vader_predictions ' + str(len(vader_predictions)))\n",
    "print(vader_predictions[:5])\n",
    "\n",
    "print('sentiwordnet_predictions ' + str(len(sentiwordnet_predictions)))\n",
    "print(sentiwordnet_predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFINN Classification {'negative': 497, 'positive': 8178}\n",
      "VADER Classification {'negative': 186, 'positive': 8489}\n",
      "SentiWordNet Classification {'negative': 105, 'positive': 8570}\n"
     ]
    }
   ],
   "source": [
    "#Print Classification Summary\n",
    "print('AFINN Classification ' + str(freq(afinn_score_final)))\n",
    "print('VADER Classification ' + str(freq(vader_predictions)))\n",
    "print('SentiWordNet Classification ' + str(freq(sentiwordnet_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   type     afinn     vader     senti      concur\n",
      "0  INFJ  positive  positive  positive  concurrent\n",
      "1  ENTP  positive  positive  positive  concurrent\n",
      "2  INTP  positive  positive  positive  concurrent\n",
      "3  INTJ  positive  positive  positive  concurrent\n",
      "4  ENTJ  positive  positive  positive  concurrent\n",
      "\n",
      "concurrent    0.95562\n",
      "not           0.04438\n",
      "Name: concur, dtype: float64\n",
      "\n",
      "afinn     concur    \n",
      "negative  not           0.663984\n",
      "          concurrent    0.336016\n",
      "positive  concurrent    0.993275\n",
      "          not           0.006725\n",
      "Name: concur, dtype: float64\n",
      "\n",
      "type  concur    \n",
      "ENFJ  concurrent    0.978947\n",
      "      not           0.021053\n",
      "ENFP  concurrent    0.983704\n",
      "      not           0.016296\n",
      "ENTJ  concurrent    0.961039\n",
      "      not           0.038961\n",
      "ENTP  concurrent    0.941606\n",
      "      not           0.058394\n",
      "ESFJ  concurrent    1.000000\n",
      "ESFP  concurrent    0.937500\n",
      "      not           0.062500\n",
      "ESTJ  concurrent    0.974359\n",
      "      not           0.025641\n",
      "ESTP  concurrent    0.932584\n",
      "      not           0.067416\n",
      "INFJ  concurrent    0.967347\n",
      "      not           0.032653\n",
      "INFP  concurrent    0.960153\n",
      "      not           0.039847\n",
      "INTJ  concurrent    0.940422\n",
      "      not           0.059578\n",
      "INTP  concurrent    0.932515\n",
      "      not           0.067485\n",
      "ISFJ  concurrent    0.975904\n",
      "      not           0.024096\n",
      "ISFP  concurrent    0.970480\n",
      "      not           0.029520\n",
      "ISTJ  concurrent    0.995122\n",
      "      not           0.004878\n",
      "ISTP  concurrent    0.928783\n",
      "      not           0.071217\n",
      "Name: concur, dtype: float64\n",
      "\n",
      "type  afinn     concur    \n",
      "ENFJ  negative  not           0.571429\n",
      "                concurrent    0.428571\n",
      "      positive  concurrent    1.000000\n",
      "ENFP  negative  not           0.615385\n",
      "                concurrent    0.384615\n",
      "      positive  concurrent    0.995468\n",
      "                not           0.004532\n",
      "ENTJ  negative  not           0.666667\n",
      "                concurrent    0.333333\n",
      "      positive  concurrent    0.995434\n",
      "                not           0.004566\n",
      "ENTP  negative  not           0.634615\n",
      "                concurrent    0.365385\n",
      "      positive  concurrent    0.988942\n",
      "                not           0.011058\n",
      "ESFJ  positive  concurrent    1.000000\n",
      "ESFP  negative  not           0.750000\n",
      "                concurrent    0.250000\n",
      "      positive  concurrent    1.000000\n",
      "ESTJ  negative  concurrent    0.666667\n",
      "                not           0.333333\n",
      "      positive  concurrent    1.000000\n",
      "ESTP  negative  not           1.000000\n",
      "      positive  concurrent    0.988095\n",
      "                not           0.011905\n",
      "INFJ  negative  not           0.782609\n",
      "                concurrent    0.217391\n",
      "      positive  concurrent    0.991573\n",
      "                not           0.008427\n",
      "INFP  negative  not           0.688172\n",
      "                concurrent    0.311828\n",
      "      positive  concurrent    0.994825\n",
      "                not           0.005175\n",
      "INTJ  negative  not           0.606742\n",
      "                concurrent    0.393258\n",
      "      positive  concurrent    0.989022\n",
      "                not           0.010978\n",
      "INTP  negative  not           0.681034\n",
      "                concurrent    0.318966\n",
      "      positive  concurrent    0.992424\n",
      "                not           0.007576\n",
      "ISFJ  negative  concurrent    0.500000\n",
      "                not           0.500000\n",
      "      positive  concurrent    0.993750\n",
      "                not           0.006250\n",
      "ISFP  negative  not           0.875000\n",
      "                concurrent    0.125000\n",
      "      positive  concurrent    0.996198\n",
      "                not           0.003802\n",
      "ISTJ  negative  concurrent    0.857143\n",
      "                not           0.142857\n",
      "      positive  concurrent    1.000000\n",
      "ISTP  negative  not           0.666667\n",
      "                concurrent    0.333333\n",
      "      positive  concurrent    1.000000\n",
      "Name: concur, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "type = cleaned_mbti_userlvl['type']\n",
    "AFINN = pd.DataFrame(afinn_score_final, columns=['afinn'])\n",
    "VADER = pd.DataFrame(vader_predictions, columns=['vader'])\n",
    "SentiWord = pd.DataFrame(sentiwordnet_predictions, columns=['senti'])\n",
    "\n",
    "Combined = pd.concat([type, AFINN, VADER, SentiWord], axis=1)\n",
    "Combined['concur'] = np.where((Combined['afinn'] >= Combined['vader']) & (Combined['afinn'] <= Combined['senti'])\n",
    "                     , 'concurrent', 'not')\n",
    "\n",
    "\n",
    "print(Combined.head())\n",
    "print()\n",
    "\n",
    "counts = Combined.concur.value_counts(normalize=True)\n",
    "print(counts)\n",
    "print()\n",
    "\n",
    "counts = Combined.groupby('afinn').concur.value_counts(normalize=True)\n",
    "print(counts)\n",
    "print()\n",
    "\n",
    "counts = Combined.groupby('type').concur.value_counts(normalize=True)\n",
    "print(counts)\n",
    "print()\n",
    "\n",
    "counts = Combined.groupby(['type','afinn']).concur.value_counts(normalize=True)\n",
    "print(counts)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Comments:\n",
    "    - Using the user level data inplies that overal the comment corpus's of each user are positive in nature. \n",
    "    - All three lexicon based approaches support this conclusion that the comments are overal postive.\n",
    "    - The concurrency across MBTI types is fairly stable with 4% of users having non concurrent estimates and each MBTI type\n",
    "        having around 4% non concurrence. \n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
