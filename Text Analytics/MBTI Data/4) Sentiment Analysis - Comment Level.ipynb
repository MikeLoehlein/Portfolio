{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''4) Sentiment Analysis'''\n",
    "\n",
    "'''\n",
    "This file takes the comment level cleaned data from 1) Data Prep and preforms unsupervised sentiment analysis on it. \n",
    "The code uses three seperate lexicon based scoring methods and compares the results across the users. \n",
    "\n",
    "The code does the following:\n",
    " - Import libraries\n",
    " - Defines functions\n",
    " - Subsets and formats the data. This process uses the cleaned and processed data, not the raw comments.\n",
    " - Scores the data\n",
    " - Compares the scored sentiment accoring to 1) overal and 2) MBTI type.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libaries and Modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import nltk\n",
    "\n",
    "from afinn import Afinn\n",
    "afn = Afinn(emoticons=False) \n",
    "\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from normalization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Define Functions\n",
    "def analyze_sentiment_sentiwordnet_lexicon(review):\n",
    "    # tokenize and POS tag text tokens\n",
    "    text_tokens = nltk.word_tokenize(review)\n",
    "    tagged_text = nltk.pos_tag(text_tokens)\n",
    "    pos_score = neg_score = token_count = obj_score = 0\n",
    "    # get wordnet synsets based on POS tags\n",
    "    # get sentiment scores if synsets are found\n",
    "    for word, tag in tagged_text:\n",
    "        ss_set = None\n",
    "        if 'NN' in tag and swn.senti_synsets(word, 'n'):\n",
    "            ss_set = list(swn.senti_synsets(word, 'n'))\n",
    "        elif 'VB' in tag and swn.senti_synsets(word, 'v'):\n",
    "            ss_set = list(swn.senti_synsets(word, 'v'))\n",
    "        elif 'JJ' in tag and swn.senti_synsets(word, 'a'):\n",
    "            ss_set = list(swn.senti_synsets(word, 'a'))\n",
    "        elif 'RB' in tag and swn.senti_synsets(word, 'r'):\n",
    "            ss_set = list(swn.senti_synsets(word, 'r'))\n",
    "        # if senti-synset is found        \n",
    "        if ss_set:\n",
    "            ss_set = ss_set[0]\n",
    "            # add scores for all found synsets\n",
    "            pos_score += ss_set.pos_score()\n",
    "            neg_score += ss_set.neg_score()\n",
    "            obj_score += ss_set.obj_score()\n",
    "            token_count += 1\n",
    "    \n",
    "    # aggregate final scores\n",
    "    try:\n",
    "        final_score = pos_score - neg_score\n",
    "        norm_final_score = round(float(final_score) / token_count, 2)\n",
    "        final_sentiment = 'positive' if norm_final_score >= 0 else 'negative'\n",
    "    except:\n",
    "        final_sentiment = 'Not Evaluated'\n",
    "        \n",
    "    return final_sentiment\n",
    "\n",
    "def analyze_sentiment_vader_lexicon(review, \n",
    "                                    threshold=0.1):\n",
    "    # analyze the sentiment for review\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    scores = analyzer.polarity_scores(review)\n",
    "    # get aggregate scores and final sentiment\n",
    "    agg_score = scores['compound']\n",
    "    final_sentiment = 'positive' if agg_score >= threshold\\\n",
    "                                   else 'negative'\n",
    "   \n",
    "    return final_sentiment\n",
    "\n",
    "def freq(lst):\n",
    "    d = {}\n",
    "    for i in lst:\n",
    "        if d.get(i):\n",
    "            d[i] += 1\n",
    "        else:\n",
    "            d[i] = 1\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Data\n",
    "cleaned_mbti_userlvl = pd.read_pickle('cleaned_mbti_cmtlvl.pkl')\n",
    "comments = np.array(cleaned_mbti_userlvl['clean_comment']) #Cast to an array\n",
    "print(cleaned_mbti_userlvl.head(2))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#AFINN Sentiment Analysis Scoring\n",
    "afinn_score = [afn.score(review) for review in comments]\n",
    "\n",
    "afinn_score_final = []\n",
    "\n",
    "for x in afinn_score:\n",
    "    if x > 0:\n",
    "        hold = 'positive'\n",
    "    else:\n",
    "        hold = \"negative\"\n",
    "    afinn_score_final.append(hold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sentiment Analysis using Vader Lexicon\n",
    "vader_predictions = [analyze_sentiment_vader_lexicon(review, threshold=0.1) for review in comments] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sentiment Analysis using SentiWord Lexicon\n",
    "sentiwordnet_predictions = [analyze_sentiment_sentiwordnet_lexicon(review) for review in comments]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print Scores for first five\n",
    "print('afinn_score ' + str(len(afinn_score_final)))\n",
    "print(afinn_score_final[:5])\n",
    "\n",
    "print('vader_predictions ' + str(len(vader_predictions)))\n",
    "print(vader_predictions[:5])\n",
    "\n",
    "print('sentiwordnet_predictions ' + str(len(sentiwordnet_predictions)))\n",
    "print(sentiwordnet_predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print Classification Summary\n",
    "print('AFINN Classification ' + str(freq(afinn_score_final)))\n",
    "print('VADER Classification ' + str(freq(vader_predictions)))\n",
    "print('SentiWordNet Classification ' + str(freq(sentiwordnet_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type = cleaned_mbti_userlvl['type']\n",
    "AFINN = pd.DataFrame(afinn_score_final, columns=['afinn'])\n",
    "VADER = pd.DataFrame(vader_predictions, columns=['vader'])\n",
    "SentiWord = pd.DataFrame(sentiwordnet_predictions, columns=['senti'])\n",
    "\n",
    "Combined = pd.concat([type, AFINN, VADER, SentiWord], axis=1)\n",
    "Combined['concur'] = np.where((Combined['afinn'] >= Combined['vader']) & (Combined['afinn'] <= Combined['senti'])\n",
    "                     , 'concurrent', 'not')\n",
    "\n",
    "\n",
    "print(Combined.head())\n",
    "print()\n",
    "\n",
    "counts = Combined.concur.value_counts(normalize=True)\n",
    "print(counts)\n",
    "print()\n",
    "\n",
    "counts = Combined.groupby('afinn').concur.value_counts(normalize=True)\n",
    "print(counts)\n",
    "print()\n",
    "\n",
    "counts = Combined.groupby('type').concur.value_counts(normalize=True)\n",
    "print(counts)\n",
    "print()\n",
    "\n",
    "counts = Combined.groupby(['type','afinn']).concur.value_counts(normalize=True)\n",
    "print(counts)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Comments:\n",
    "    - Using the comment level data inplies that overal the comments are at least 50% positive. Depending on the lexicon used \n",
    "    the positive vs negatiev ratio goes from 50% postive to about 75% positive. \n",
    "    \n",
    "    - Across MBTI type, the percent of comment which the three lexicons scored as conccurrent (so all three as positive or \n",
    "    all three as negative is farily stable with around 20% non currence by MBTI and scoring (positive vs negative)).\n",
    "    \n",
    "    - The comments which are concurrent (so all positive or all negative) are likely properly scored. However the non current \n",
    "    comments should be mannually reviewed and classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
